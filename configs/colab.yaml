# Colab training configuration.
# Optimized for T4 GPU with small dataset.

model:
  name: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
  quantization:
    enabled: true
    bits: 4
    quant_type: "nf4"
    compute_dtype: "bfloat16"
  max_length: 512

adapter:
  type: "lora"
  r: 16
  alpha: 32
  dropout: 0.05
  target_modules:
    - "q_proj"
    - "v_proj"
    - "k_proj"
    - "o_proj"

data:
  source: "outputs/data/Anthropic_hh-rlhf_manifest.json"
  train_split: "train"
  # Already constrained by manifest, but good for safety
  max_samples: 1000
  preprocessing:
    max_completion_length: 256

training:
  algorithm: "dpo"
  output_dir: "outputs"
  num_epochs: 1
  batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 5.0e-5
  warmup_ratio: 0.1
  weight_decay: 0.01
  max_grad_norm: 1.0
  seed: 42
  fp16: false
  bf16: true
  logging_steps: 10
  eval_steps: 25
  save_steps: 50

dpo:
  beta: 0.1
  loss_type: "sigmoid"

telemetry:
  enabled: true
  log_dir: "logs"
